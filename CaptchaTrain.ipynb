{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from nets import nets_factory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SET_LEN = 10\n",
    "IMAGE_HEIGHT = 60\n",
    "IMAGE_WIDTH = 160\n",
    "BATCH_SIZE = 30\n",
    "TFRECORD_FILE = \"./captcha-tfrecords/train.tfrecords\"\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224])\n",
    "y0 = tf.placeholder(tf.float32, [None])\n",
    "y1 = tf.placeholder(tf.float32, [None])\n",
    "y2 = tf.placeholder(tf.float32, [None])\n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "# learning rate\n",
    "lr = tf.Variable(0.001, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from tfrecord\n",
    "def read_and_decode(filename):\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'image': tf.FixedLenFeature([], tf.string),\n",
    "                                           'label0': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label1': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label2': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label3': tf.FixedLenFeature([], tf.int64)\n",
    "                                       })\n",
    "    # get images\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [224, 224])\n",
    "    # preprocess images\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    # get labels\n",
    "    label0 = tf.cast(features['label0'], tf.int32)\n",
    "    label1 = tf.cast(features['label1'], tf.int32)\n",
    "    label2 = tf.cast(features['label2'], tf.int32)\n",
    "    label3 = tf.cast(features['label3'], tf.int32)\n",
    "\n",
    "    return image, label0, label1, label2, label3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0  Loss:6.998  Accuracy:0.17,0.17,0.30,0.27  Learning-Rate:0.0003\n",
      "Iter:20  Loss:2.307  Accuracy:0.20,0.10,0.07,0.10  Learning-Rate:0.0003\n",
      "Iter:40  Loss:2.287  Accuracy:0.13,0.17,0.17,0.10  Learning-Rate:0.0003\n",
      "Iter:60  Loss:2.282  Accuracy:0.07,0.17,0.07,0.10  Learning-Rate:0.0003\n",
      "Iter:80  Loss:2.307  Accuracy:0.00,0.03,0.00,0.20  Learning-Rate:0.0003\n",
      "Iter:100  Loss:2.309  Accuracy:0.13,0.10,0.13,0.03  Learning-Rate:0.0003\n",
      "Iter:120  Loss:2.312  Accuracy:0.13,0.00,0.07,0.00  Learning-Rate:0.0003\n",
      "Iter:140  Loss:2.317  Accuracy:0.13,0.07,0.07,0.03  Learning-Rate:0.0003\n",
      "Iter:160  Loss:2.305  Accuracy:0.10,0.13,0.03,0.13  Learning-Rate:0.0003\n",
      "Iter:180  Loss:2.300  Accuracy:0.07,0.03,0.07,0.23  Learning-Rate:0.0003\n",
      "Iter:200  Loss:2.301  Accuracy:0.00,0.17,0.10,0.10  Learning-Rate:0.0003\n",
      "Iter:220  Loss:2.305  Accuracy:0.17,0.07,0.20,0.07  Learning-Rate:0.0003\n",
      "Iter:240  Loss:2.308  Accuracy:0.27,0.07,0.10,0.03  Learning-Rate:0.0003\n",
      "Iter:260  Loss:2.299  Accuracy:0.07,0.07,0.07,0.13  Learning-Rate:0.0003\n",
      "Iter:280  Loss:2.296  Accuracy:0.17,0.07,0.00,0.23  Learning-Rate:0.0003\n",
      "Iter:300  Loss:2.301  Accuracy:0.07,0.10,0.27,0.07  Learning-Rate:0.0003\n",
      "Iter:320  Loss:2.312  Accuracy:0.07,0.17,0.13,0.10  Learning-Rate:0.0003\n",
      "Iter:340  Loss:2.298  Accuracy:0.13,0.07,0.10,0.07  Learning-Rate:0.0003\n",
      "Iter:360  Loss:2.272  Accuracy:0.37,0.23,0.07,0.07  Learning-Rate:0.0003\n",
      "Iter:380  Loss:2.264  Accuracy:0.10,0.03,0.03,0.03  Learning-Rate:0.0003\n",
      "Iter:400  Loss:2.218  Accuracy:0.27,0.03,0.10,0.07  Learning-Rate:0.0003\n",
      "Iter:420  Loss:2.203  Accuracy:0.37,0.07,0.17,0.23  Learning-Rate:0.0003\n",
      "Iter:440  Loss:2.239  Accuracy:0.20,0.20,0.10,0.13  Learning-Rate:0.0003\n",
      "Iter:460  Loss:2.204  Accuracy:0.23,0.07,0.07,0.07  Learning-Rate:0.0003\n",
      "Iter:480  Loss:2.079  Accuracy:0.43,0.23,0.03,0.13  Learning-Rate:0.0003\n",
      "Iter:500  Loss:2.059  Accuracy:0.43,0.17,0.03,0.10  Learning-Rate:0.0003\n",
      "Iter:520  Loss:2.047  Accuracy:0.50,0.17,0.13,0.13  Learning-Rate:0.0003\n",
      "Iter:540  Loss:1.949  Accuracy:0.30,0.23,0.27,0.23  Learning-Rate:0.0003\n",
      "Iter:560  Loss:1.801  Accuracy:0.43,0.23,0.20,0.37  Learning-Rate:0.0003\n",
      "Iter:580  Loss:1.844  Accuracy:0.37,0.17,0.13,0.33  Learning-Rate:0.0003\n",
      "Iter:600  Loss:1.695  Accuracy:0.57,0.23,0.37,0.40  Learning-Rate:0.0003\n",
      "Iter:620  Loss:1.645  Accuracy:0.60,0.30,0.30,0.37  Learning-Rate:0.0003\n",
      "Iter:640  Loss:1.368  Accuracy:0.73,0.53,0.40,0.53  Learning-Rate:0.0003\n",
      "Iter:660  Loss:1.334  Accuracy:0.57,0.37,0.47,0.47  Learning-Rate:0.0003\n",
      "Iter:680  Loss:1.392  Accuracy:0.63,0.63,0.23,0.50  Learning-Rate:0.0003\n",
      "Iter:700  Loss:1.261  Accuracy:0.60,0.47,0.43,0.50  Learning-Rate:0.0003\n",
      "Iter:720  Loss:1.019  Accuracy:0.80,0.47,0.53,0.70  Learning-Rate:0.0003\n",
      "Iter:740  Loss:1.133  Accuracy:0.70,0.70,0.53,0.47  Learning-Rate:0.0003\n",
      "Iter:760  Loss:1.078  Accuracy:0.80,0.53,0.60,0.60  Learning-Rate:0.0003\n",
      "Iter:780  Loss:0.887  Accuracy:0.87,0.70,0.57,0.67  Learning-Rate:0.0003\n",
      "Iter:800  Loss:0.949  Accuracy:0.83,0.73,0.53,0.70  Learning-Rate:0.0003\n",
      "Iter:820  Loss:0.740  Accuracy:0.83,0.67,0.67,0.87  Learning-Rate:0.0003\n",
      "Iter:840  Loss:0.717  Accuracy:0.63,0.70,0.70,0.73  Learning-Rate:0.0003\n",
      "Iter:860  Loss:0.920  Accuracy:0.80,0.70,0.40,0.70  Learning-Rate:0.0003\n",
      "Iter:880  Loss:0.755  Accuracy:0.70,0.70,0.80,0.70  Learning-Rate:0.0003\n",
      "Iter:900  Loss:0.706  Accuracy:0.80,0.70,0.47,0.77  Learning-Rate:0.0003\n",
      "Iter:920  Loss:0.592  Accuracy:0.80,0.67,0.70,0.83  Learning-Rate:0.0003\n",
      "Iter:940  Loss:0.612  Accuracy:0.80,0.73,0.77,0.80  Learning-Rate:0.0003\n",
      "Iter:960  Loss:0.558  Accuracy:0.97,0.80,0.63,0.80  Learning-Rate:0.0003\n",
      "Iter:980  Loss:0.497  Accuracy:0.97,0.80,0.87,0.77  Learning-Rate:0.0003\n",
      "Iter:1000  Loss:0.420  Accuracy:0.87,0.90,0.67,0.90  Learning-Rate:0.0003\n",
      "Iter:1020  Loss:0.574  Accuracy:0.90,0.80,0.67,0.87  Learning-Rate:0.0003\n",
      "Iter:1040  Loss:0.419  Accuracy:0.87,0.87,0.80,0.87  Learning-Rate:0.0003\n",
      "Iter:1060  Loss:0.415  Accuracy:0.90,0.87,0.90,0.77  Learning-Rate:0.0003\n",
      "Iter:1080  Loss:0.423  Accuracy:0.90,0.80,0.80,0.90  Learning-Rate:0.0003\n",
      "Iter:1100  Loss:0.371  Accuracy:0.83,0.80,0.83,0.90  Learning-Rate:0.0003\n",
      "Iter:1120  Loss:0.364  Accuracy:0.93,0.93,0.87,0.73  Learning-Rate:0.0003\n",
      "Iter:1140  Loss:0.398  Accuracy:0.97,0.80,0.90,0.83  Learning-Rate:0.0003\n",
      "Iter:1160  Loss:0.365  Accuracy:0.90,0.93,0.87,0.83  Learning-Rate:0.0003\n",
      "Iter:1180  Loss:0.258  Accuracy:0.97,0.87,0.90,0.90  Learning-Rate:0.0003\n",
      "Iter:1200  Loss:0.266  Accuracy:1.00,0.80,0.87,0.90  Learning-Rate:0.0003\n",
      "Iter:1220  Loss:0.452  Accuracy:0.93,0.80,0.87,0.77  Learning-Rate:0.0003\n",
      "Iter:1240  Loss:0.261  Accuracy:0.93,0.90,0.93,0.93  Learning-Rate:0.0003\n",
      "Iter:1260  Loss:0.459  Accuracy:0.90,0.80,0.70,0.90  Learning-Rate:0.0003\n",
      "Iter:1280  Loss:0.263  Accuracy:0.90,0.90,0.93,0.90  Learning-Rate:0.0003\n",
      "Iter:1300  Loss:0.390  Accuracy:0.93,0.93,0.77,0.87  Learning-Rate:0.0003\n",
      "Iter:1320  Loss:0.211  Accuracy:0.97,0.87,0.90,0.93  Learning-Rate:0.0003\n",
      "Iter:1340  Loss:0.254  Accuracy:0.93,0.90,0.87,1.00  Learning-Rate:0.0003\n",
      "Iter:1360  Loss:0.261  Accuracy:0.97,0.93,0.93,0.90  Learning-Rate:0.0003\n",
      "Iter:1380  Loss:0.129  Accuracy:0.97,0.93,0.90,1.00  Learning-Rate:0.0003\n",
      "Iter:1400  Loss:0.121  Accuracy:0.97,0.93,0.97,1.00  Learning-Rate:0.0003\n",
      "Iter:1420  Loss:0.136  Accuracy:0.97,0.97,0.90,0.97  Learning-Rate:0.0003\n",
      "Iter:1440  Loss:0.161  Accuracy:0.87,1.00,0.97,0.93  Learning-Rate:0.0003\n",
      "Iter:1460  Loss:0.209  Accuracy:0.90,0.87,0.90,0.97  Learning-Rate:0.0003\n",
      "Iter:1480  Loss:0.120  Accuracy:0.97,0.97,0.97,1.00  Learning-Rate:0.0003\n",
      "Iter:1500  Loss:0.146  Accuracy:0.97,0.97,0.87,1.00  Learning-Rate:0.0003\n",
      "Iter:1520  Loss:0.096  Accuracy:1.00,0.97,1.00,0.93  Learning-Rate:0.0003\n",
      "Iter:1540  Loss:0.164  Accuracy:1.00,0.90,0.93,1.00  Learning-Rate:0.0003\n",
      "Iter:1560  Loss:0.233  Accuracy:0.97,0.77,0.90,0.97  Learning-Rate:0.0003\n",
      "Iter:1580  Loss:0.146  Accuracy:0.93,0.93,0.90,0.97  Learning-Rate:0.0003\n",
      "Iter:1600  Loss:0.105  Accuracy:0.97,0.97,0.93,0.97  Learning-Rate:0.0003\n",
      "Iter:1620  Loss:0.185  Accuracy:0.97,0.93,0.93,0.93  Learning-Rate:0.0003\n",
      "Iter:1640  Loss:0.169  Accuracy:0.97,0.87,0.90,0.97  Learning-Rate:0.0003\n",
      "Iter:1660  Loss:0.074  Accuracy:1.00,1.00,0.97,0.97  Learning-Rate:0.0003\n",
      "Iter:1680  Loss:0.166  Accuracy:0.87,0.93,0.97,1.00  Learning-Rate:0.0003\n",
      "Iter:1700  Loss:0.089  Accuracy:1.00,0.93,1.00,0.93  Learning-Rate:0.0003\n",
      "Iter:1720  Loss:0.106  Accuracy:1.00,0.93,0.93,0.90  Learning-Rate:0.0003\n",
      "Iter:1740  Loss:0.033  Accuracy:1.00,0.97,1.00,1.00  Learning-Rate:0.0003\n",
      "Iter:1760  Loss:0.071  Accuracy:1.00,1.00,0.87,1.00  Learning-Rate:0.0003\n",
      "Iter:1780  Loss:0.115  Accuracy:0.93,0.93,0.97,0.97  Learning-Rate:0.0003\n",
      "Iter:1800  Loss:0.179  Accuracy:0.97,0.97,0.90,0.93  Learning-Rate:0.0003\n",
      "Iter:1820  Loss:0.062  Accuracy:1.00,1.00,1.00,0.97  Learning-Rate:0.0003\n",
      "Iter:1840  Loss:0.172  Accuracy:0.93,0.97,0.93,0.97  Learning-Rate:0.0003\n",
      "Iter:1860  Loss:0.095  Accuracy:1.00,0.97,0.93,0.97  Learning-Rate:0.0003\n",
      "Iter:1880  Loss:0.159  Accuracy:1.00,0.90,0.90,0.97  Learning-Rate:0.0003\n",
      "Iter:1900  Loss:0.064  Accuracy:0.97,1.00,1.00,1.00  Learning-Rate:0.0003\n",
      "Iter:1920  Loss:0.081  Accuracy:0.97,1.00,0.97,1.00  Learning-Rate:0.0003\n",
      "Iter:1940  Loss:0.067  Accuracy:0.97,1.00,0.97,0.97  Learning-Rate:0.0003\n",
      "Iter:1960  Loss:0.140  Accuracy:0.93,0.93,0.93,0.97  Learning-Rate:0.0003\n",
      "Iter:1980  Loss:0.098  Accuracy:0.97,1.00,0.93,1.00  Learning-Rate:0.0003\n",
      "Iter:2000  Loss:0.054  Accuracy:1.00,1.00,0.97,0.93  Learning-Rate:0.0001\n",
      "Iter:2020  Loss:0.037  Accuracy:1.00,1.00,0.97,1.00  Learning-Rate:0.0001\n",
      "Iter:2040  Loss:0.074  Accuracy:0.93,1.00,0.93,1.00  Learning-Rate:0.0001\n",
      "Iter:2060  Loss:0.054  Accuracy:0.97,1.00,0.97,0.97  Learning-Rate:0.0001\n",
      "Iter:2080  Loss:0.075  Accuracy:0.93,0.93,1.00,1.00  Learning-Rate:0.0001\n",
      "Iter:2100  Loss:0.114  Accuracy:1.00,0.97,1.00,0.97  Learning-Rate:0.0001\n",
      "Iter:2120  Loss:0.063  Accuracy:1.00,1.00,0.97,1.00  Learning-Rate:0.0001\n",
      "Iter:2140  Loss:0.018  Accuracy:1.00,1.00,1.00,1.00  Learning-Rate:0.0001\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # get images and labels\n",
    "    image, label0, label1, label2, label3 = read_and_decode(TFRECORD_FILE)\n",
    "\n",
    "    # randomly shuffle data\n",
    "    image_batch, label_batch0, label_batch1, label_batch2, label_batch3 = tf.train.shuffle_batch(\n",
    "        [image, label0, label1, label2, label3], batch_size=BATCH_SIZE,\n",
    "        capacity=50000, min_after_dequeue=10000, num_threads=1)\n",
    "\n",
    "    # define the network structure\n",
    "    train_network_fn = nets_factory.get_network_fn(\n",
    "        'alexnet_v2',\n",
    "        num_classes=CHAR_SET_LEN,\n",
    "        weight_decay=0.0005,\n",
    "        is_training=True)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # inputs: a tensor or size [batch_size, height, width, channels]\n",
    "        X = tf.reshape(x, [BATCH_SIZE, 224, 224, 1])\n",
    "\n",
    "        logits0, logits1, logits2, logits3, end_points = train_network_fn(X)\n",
    "\n",
    "        one_hot_labels0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=CHAR_SET_LEN)\n",
    "        one_hot_labels1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=CHAR_SET_LEN)\n",
    "        one_hot_labels2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=CHAR_SET_LEN)\n",
    "        one_hot_labels3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=CHAR_SET_LEN)\n",
    "\n",
    "        loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits0, labels=one_hot_labels0))\n",
    "        loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits1, labels=one_hot_labels1))\n",
    "        loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits2, labels=one_hot_labels2))\n",
    "        loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits3, labels=one_hot_labels3))\n",
    "\n",
    "        total_loss = (loss0 + loss1 + loss2 + loss3) / 4.0\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss)\n",
    "\n",
    "        correct_prediction0 = tf.equal(tf.argmax(one_hot_labels0, 1), tf.argmax(logits0, 1))\n",
    "        accuracy0 = tf.reduce_mean(tf.cast(correct_prediction0, tf.float32))\n",
    "\n",
    "        correct_prediction1 = tf.equal(tf.argmax(one_hot_labels1, 1), tf.argmax(logits1, 1))\n",
    "        accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))\n",
    "\n",
    "        correct_prediction2 = tf.equal(tf.argmax(one_hot_labels2, 1), tf.argmax(logits2, 1))\n",
    "        accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))\n",
    "\n",
    "        correct_prediction3 = tf.equal(tf.argmax(one_hot_labels3, 1), tf.argmax(logits3, 1))\n",
    "        accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3, tf.float32))\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        for i in range(10001):\n",
    "            b_image, b_label0, b_label1, b_label2, b_label3 = sess.run([image_batch, label_batch0, label_batch1, label_batch2, label_batch3])\n",
    "            sess.run(optimizer, feed_dict={x: b_image, y0: b_label0, y1: b_label1, y2: b_label2, y3: b_label3})\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                if i % 2000 == 0:\n",
    "                    sess.run(tf.assign(lr, lr / 3))\n",
    "                acc0, acc1, acc2, acc3, loss_ = sess.run([accuracy0, accuracy1, accuracy2, accuracy3, total_loss],\n",
    "                                                         feed_dict={x: b_image, y0: b_label0, y1: b_label1, y2:b_label2, y3: b_label3})\n",
    "\n",
    "                learning_rate = sess.run(lr)\n",
    "\n",
    "                print(\"Iter:%d  Loss:%.3f  Accuracy:%.2f,%.2f,%.2f,%.2f  Learning-Rate:%.4f\" %(i, loss_, acc0, acc1, acc2, acc3, learning_rate))\n",
    "                if not os.path.exists('./captcha-models'):\n",
    "                    os.mkdir('./captcha-models')\n",
    "                \n",
    "                if acc0 > 0.98 and acc1 > 0.98 and acc2 > 0.98 and acc3 > 0.98:\n",
    "                    saver.save(sess, './captcha-models/crack_captcha.model', global_step=i)\n",
    "                    break\n",
    "                    \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
